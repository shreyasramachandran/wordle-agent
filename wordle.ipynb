{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b01c4d82",
   "metadata": {},
   "source": [
    "Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37e75f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary - 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/plaksha/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('words')\n",
    "from nltk.corpus import words\n",
    "\n",
    "vocab = [w.lower() for w in words.words() if len(w) == 5 and w.isalpha()]\n",
    "vocab = list(set(vocab))\n",
    "print('Length of vocabulary -', len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071b6e93",
   "metadata": {},
   "source": [
    "Wordle Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "942254ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_gen_fn():\n",
    "    import random\n",
    "    return random.choice(vocab)\n",
    "\n",
    "class WordleEnv:\n",
    "    def __init__(self,word_gen_fn):\n",
    "        self.word_gen_fn = word_gen_fn\n",
    "        self.max_turns = 6\n",
    "\n",
    "    def reset(self):\n",
    "        self.answer = self.word_gen_fn()\n",
    "        self.history = []\n",
    "        return \"\"  # empty state initially\n",
    "\n",
    "    def _generate_feedback(self, guess, answer):\n",
    "        feedback = [\"â¬›\"] * 5\n",
    "        answer_chars = list(answer)\n",
    "        used = [False] * 5\n",
    "\n",
    "        # First pass: correct letters (green)\n",
    "        for i in range(5):\n",
    "            if guess[i] == answer[i]:\n",
    "                feedback[i] = \"ðŸŸ©\"\n",
    "                used[i] = True\n",
    "\n",
    "        # Second pass: present letters (yellow)\n",
    "        for i in range(5):\n",
    "            if feedback[i] == \"ðŸŸ©\":\n",
    "                continue\n",
    "            for j in range(5):\n",
    "                if guess[i] == answer_chars[j] and not used[j]:\n",
    "                    feedback[i] = \"ðŸŸ¨\"\n",
    "                    used[j] = True\n",
    "                    break\n",
    "\n",
    "        return \"\".join(feedback)\n",
    "\n",
    "    def step(self, guess):\n",
    "        feedback = self._generate_feedback(guess, self.answer)\n",
    "        self.history.append((guess, feedback))\n",
    "        done = guess == self.answer or len(self.history) >= self.max_turns\n",
    "        solved = guess == self.answer\n",
    "\n",
    "        # Reward shaping\n",
    "        base_reward = (\n",
    "            0.1 * feedback.count(\"ðŸŸ©\") + \n",
    "            0.05 * feedback.count(\"ðŸŸ¨\")\n",
    "        )\n",
    "        if solved:\n",
    "            base_reward += 1 / (1 + len(self.history))\n",
    "\n",
    "        binary_success = 1.0 if solved else 0.0\n",
    "        total_reward = base_reward + binary_success\n",
    "        return feedback, done, total_reward\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58dc007",
   "metadata": {},
   "source": [
    "Policy Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ca14696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class WordlePolicy(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        # +4 = vocab + 3 color tokens + 1 START token\n",
    "        self.embed = nn.Embedding(vocab_size + 1, embed_dim)\n",
    "        self.rnn = nn.GRU(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, state_seq):  # state_seq = tokenized sequence of guess-feedback\n",
    "        x = self.embed(state_seq)\n",
    "        _, h = self.rnn(x)\n",
    "        logits = self.fc(h.squeeze(0))\n",
    "        return F.log_softmax(logits, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad1f481",
   "metadata": {},
   "source": [
    "Tokenizer + Vocab Indexing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c5d068d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocab mappings\n",
    "word2idx = {word: i for i, word in enumerate(vocab)}\n",
    "idx2word = {i: word for word, i in word2idx.items()}\n",
    "\n",
    "# Simple tokenizer for (guess, feedback) history\n",
    "def tokenize_history(history):\n",
    "    # Each guess-feedback pair becomes a sequence of integers\n",
    "    # e.g., craneðŸŸ©â¬›ðŸŸ¨â¬›â¬› becomes token ids [word_idx, green, black, yellow, ...]\n",
    "    color2id = {\"â¬›\": 0, \"ðŸŸ¨\": 1, \"ðŸŸ©\": 2}\n",
    "    tokens = [len(vocab) + 3]  # START token at index = len(vocab) + 3\n",
    "    for guess, feedback in history:\n",
    "        tokens.append(word2idx[guess])\n",
    "        tokens.extend([len(vocab) + color2id[c] for c in feedback])  # color ids shifted\n",
    "    return torch.tensor(tokens, dtype=torch.long).unsqueeze(0)  # Ensure LongTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbac287",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1752c7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100, Avg Reward: 0.934\n",
      "Episode 200, Avg Reward: 0.826\n",
      "Episode 300, Avg Reward: 0.798\n",
      "Episode 400, Avg Reward: 0.834\n",
      "Episode 500, Avg Reward: 0.930\n",
      "Episode 600, Avg Reward: 0.869\n",
      "Episode 700, Avg Reward: 0.888\n",
      "Episode 800, Avg Reward: 0.833\n",
      "Episode 900, Avg Reward: 1.195\n",
      "Episode 1000, Avg Reward: 0.898\n",
      "Episode 1100, Avg Reward: 0.841\n",
      "Episode 1200, Avg Reward: 0.845\n",
      "Episode 1300, Avg Reward: 0.989\n",
      "Episode 1400, Avg Reward: 0.957\n",
      "Episode 1500, Avg Reward: 0.932\n",
      "Episode 1600, Avg Reward: 0.884\n",
      "Episode 1700, Avg Reward: 1.109\n",
      "Episode 1800, Avg Reward: 1.122\n",
      "Episode 1900, Avg Reward: 1.085\n",
      "Episode 2000, Avg Reward: 1.325\n",
      "Episode 2100, Avg Reward: 1.305\n",
      "Episode 2200, Avg Reward: 1.235\n",
      "Episode 2300, Avg Reward: 1.140\n",
      "Episode 2400, Avg Reward: 1.257\n",
      "Episode 2500, Avg Reward: 1.291\n",
      "Episode 2600, Avg Reward: 1.315\n",
      "Episode 2700, Avg Reward: 1.466\n",
      "Episode 2800, Avg Reward: 1.533\n",
      "Episode 2900, Avg Reward: 1.376\n",
      "Episode 3000, Avg Reward: 1.288\n",
      "Episode 3100, Avg Reward: 1.430\n",
      "Episode 3200, Avg Reward: 1.502\n",
      "Episode 3300, Avg Reward: 1.511\n",
      "Episode 3400, Avg Reward: 1.531\n",
      "Episode 3500, Avg Reward: 1.463\n",
      "Episode 3600, Avg Reward: 1.493\n",
      "Episode 3700, Avg Reward: 1.517\n",
      "Episode 3800, Avg Reward: 1.501\n",
      "Episode 3900, Avg Reward: 1.496\n",
      "Episode 4000, Avg Reward: 1.544\n",
      "Episode 4100, Avg Reward: 1.625\n",
      "Episode 4200, Avg Reward: 1.666\n",
      "Episode 4300, Avg Reward: 1.648\n",
      "Episode 4400, Avg Reward: 1.669\n",
      "Episode 4500, Avg Reward: 1.641\n",
      "Episode 4600, Avg Reward: 1.634\n",
      "Episode 4700, Avg Reward: 1.708\n",
      "Episode 4800, Avg Reward: 1.743\n",
      "Episode 4900, Avg Reward: 1.741\n",
      "Episode 5000, Avg Reward: 1.758\n",
      "Episode 5100, Avg Reward: 1.743\n",
      "Episode 5200, Avg Reward: 1.768\n",
      "Episode 5300, Avg Reward: 1.820\n",
      "Episode 5400, Avg Reward: 1.754\n",
      "Episode 5500, Avg Reward: 1.806\n",
      "Episode 5600, Avg Reward: 1.812\n",
      "Episode 5700, Avg Reward: 1.805\n",
      "Episode 5800, Avg Reward: 1.823\n",
      "Episode 5900, Avg Reward: 1.805\n",
      "Episode 6000, Avg Reward: 1.801\n",
      "Episode 6100, Avg Reward: 1.814\n",
      "Episode 6200, Avg Reward: 1.770\n",
      "Episode 6300, Avg Reward: 1.812\n",
      "Episode 6400, Avg Reward: 1.796\n",
      "Episode 6500, Avg Reward: 1.811\n",
      "Episode 6600, Avg Reward: 1.806\n",
      "Episode 6700, Avg Reward: 1.829\n",
      "Episode 6800, Avg Reward: 1.828\n",
      "Episode 6900, Avg Reward: 1.816\n",
      "Episode 7000, Avg Reward: 1.793\n",
      "Episode 7100, Avg Reward: 1.801\n",
      "Episode 7200, Avg Reward: 1.831\n",
      "Episode 7300, Avg Reward: 1.800\n",
      "Episode 7400, Avg Reward: 1.815\n",
      "Episode 7500, Avg Reward: 1.796\n",
      "Episode 7600, Avg Reward: 1.778\n",
      "Episode 7700, Avg Reward: 1.831\n",
      "Episode 7800, Avg Reward: 1.789\n",
      "Episode 7900, Avg Reward: 1.822\n",
      "Episode 8000, Avg Reward: 1.819\n",
      "Episode 8100, Avg Reward: 1.824\n",
      "Episode 8200, Avg Reward: 1.813\n",
      "Episode 8300, Avg Reward: 1.601\n",
      "Episode 8400, Avg Reward: 1.671\n",
      "Episode 8500, Avg Reward: 1.784\n",
      "Episode 8600, Avg Reward: 1.804\n",
      "Episode 8700, Avg Reward: 1.819\n",
      "Episode 8800, Avg Reward: 1.821\n",
      "Episode 8900, Avg Reward: 1.821\n",
      "Episode 9000, Avg Reward: 1.825\n",
      "Episode 9100, Avg Reward: 1.818\n",
      "Episode 9200, Avg Reward: 1.777\n",
      "Episode 9300, Avg Reward: 1.833\n",
      "Episode 9400, Avg Reward: 1.825\n",
      "Episode 9500, Avg Reward: 1.805\n",
      "Episode 9600, Avg Reward: 1.829\n",
      "Episode 9700, Avg Reward: 1.839\n",
      "Episode 9800, Avg Reward: 1.830\n",
      "Episode 9900, Avg Reward: 1.797\n",
      "Episode 10000, Avg Reward: 1.817\n",
      "Episode 10100, Avg Reward: 1.805\n",
      "Episode 10200, Avg Reward: 1.828\n",
      "Episode 10300, Avg Reward: 1.831\n",
      "Episode 10400, Avg Reward: 1.818\n",
      "Episode 10500, Avg Reward: 1.828\n",
      "Episode 10600, Avg Reward: 1.831\n",
      "Episode 10700, Avg Reward: 1.828\n",
      "Episode 10800, Avg Reward: 1.834\n",
      "Episode 10900, Avg Reward: 1.842\n",
      "Episode 11000, Avg Reward: 1.838\n",
      "Episode 11100, Avg Reward: 1.841\n",
      "Episode 11200, Avg Reward: 1.844\n",
      "Episode 11300, Avg Reward: 1.841\n",
      "Episode 11400, Avg Reward: 1.835\n",
      "Episode 11500, Avg Reward: 1.834\n",
      "Episode 11600, Avg Reward: 1.808\n",
      "Episode 11700, Avg Reward: 1.829\n",
      "Episode 11800, Avg Reward: 1.825\n",
      "Episode 11900, Avg Reward: 1.806\n",
      "Episode 12000, Avg Reward: 1.808\n",
      "Episode 12100, Avg Reward: 1.806\n",
      "Episode 12200, Avg Reward: 1.812\n",
      "Episode 12300, Avg Reward: 1.833\n",
      "Episode 12400, Avg Reward: 1.826\n",
      "Episode 12500, Avg Reward: 1.805\n",
      "Episode 12600, Avg Reward: 1.821\n",
      "Episode 12700, Avg Reward: 1.820\n",
      "Episode 12800, Avg Reward: 1.832\n",
      "Episode 12900, Avg Reward: 1.827\n",
      "Episode 13000, Avg Reward: 1.823\n",
      "Episode 13100, Avg Reward: 1.815\n",
      "Episode 13200, Avg Reward: 1.838\n",
      "Episode 13300, Avg Reward: 1.833\n",
      "Episode 13400, Avg Reward: 1.822\n",
      "Episode 13500, Avg Reward: 1.821\n",
      "Episode 13600, Avg Reward: 1.808\n",
      "Episode 13700, Avg Reward: 1.769\n",
      "Episode 13800, Avg Reward: 1.805\n",
      "Episode 13900, Avg Reward: 1.808\n",
      "Episode 14000, Avg Reward: 1.815\n",
      "Episode 14100, Avg Reward: 1.825\n",
      "Episode 14200, Avg Reward: 1.815\n",
      "Episode 14300, Avg Reward: 1.826\n",
      "Episode 14400, Avg Reward: 1.832\n",
      "Episode 14500, Avg Reward: 1.832\n",
      "Episode 14600, Avg Reward: 1.804\n",
      "Episode 14700, Avg Reward: 1.816\n",
      "Episode 14800, Avg Reward: 1.820\n",
      "Episode 14900, Avg Reward: 1.819\n",
      "Episode 15000, Avg Reward: 1.822\n",
      "Episode 15100, Avg Reward: 1.831\n",
      "Episode 15200, Avg Reward: 1.831\n",
      "Episode 15300, Avg Reward: 1.819\n",
      "Episode 15400, Avg Reward: 1.823\n",
      "Episode 15500, Avg Reward: 1.760\n",
      "Episode 15600, Avg Reward: 1.814\n",
      "Episode 15700, Avg Reward: 1.711\n",
      "Episode 15800, Avg Reward: 1.826\n",
      "Episode 15900, Avg Reward: 1.815\n",
      "Episode 16000, Avg Reward: 1.827\n",
      "Episode 16100, Avg Reward: 1.811\n",
      "Episode 16200, Avg Reward: 1.817\n",
      "Episode 16300, Avg Reward: 1.813\n",
      "Episode 16400, Avg Reward: 1.819\n",
      "Episode 16500, Avg Reward: 1.845\n",
      "Episode 16600, Avg Reward: 1.822\n",
      "Episode 16700, Avg Reward: 1.821\n",
      "Episode 16800, Avg Reward: 1.820\n",
      "Episode 16900, Avg Reward: 1.828\n",
      "Episode 17000, Avg Reward: 1.824\n",
      "Episode 17100, Avg Reward: 1.842\n",
      "Episode 17200, Avg Reward: 1.833\n",
      "Episode 17300, Avg Reward: 1.824\n",
      "Episode 17400, Avg Reward: 1.811\n",
      "Episode 17500, Avg Reward: 1.836\n",
      "Episode 17600, Avg Reward: 1.820\n",
      "Episode 17700, Avg Reward: 1.836\n",
      "Episode 17800, Avg Reward: 1.818\n",
      "Episode 17900, Avg Reward: 1.835\n",
      "Episode 18000, Avg Reward: 1.829\n",
      "Episode 18100, Avg Reward: 1.825\n",
      "Episode 18200, Avg Reward: 1.846\n",
      "Episode 18300, Avg Reward: 1.838\n",
      "Episode 18400, Avg Reward: 1.819\n",
      "Episode 18500, Avg Reward: 1.827\n",
      "Episode 18600, Avg Reward: 1.824\n",
      "Episode 18700, Avg Reward: 1.828\n",
      "Episode 18800, Avg Reward: 1.832\n",
      "Episode 18900, Avg Reward: 1.834\n",
      "Episode 19000, Avg Reward: 1.832\n",
      "Episode 19100, Avg Reward: 1.828\n",
      "Episode 19200, Avg Reward: 1.836\n",
      "Episode 19300, Avg Reward: 1.833\n",
      "Episode 19400, Avg Reward: 1.819\n",
      "Episode 19500, Avg Reward: 1.828\n",
      "Episode 19600, Avg Reward: 1.832\n",
      "Episode 19700, Avg Reward: 1.829\n",
      "Episode 19800, Avg Reward: 1.829\n",
      "Episode 19900, Avg Reward: 1.845\n",
      "Episode 20000, Avg Reward: 1.844\n",
      "Episode 20100, Avg Reward: 1.823\n",
      "Episode 20200, Avg Reward: 1.835\n",
      "Episode 20300, Avg Reward: 1.847\n",
      "Episode 20400, Avg Reward: 1.827\n",
      "Episode 20500, Avg Reward: 1.823\n",
      "Episode 20600, Avg Reward: 1.840\n",
      "Episode 20700, Avg Reward: 1.825\n",
      "Episode 20800, Avg Reward: 1.834\n",
      "Episode 20900, Avg Reward: 1.833\n",
      "Episode 21000, Avg Reward: 1.834\n",
      "Episode 21100, Avg Reward: 1.832\n",
      "Episode 21200, Avg Reward: 1.767\n",
      "Episode 21300, Avg Reward: 1.716\n",
      "Episode 21400, Avg Reward: 1.583\n",
      "Episode 21500, Avg Reward: 1.754\n",
      "Episode 21600, Avg Reward: 1.834\n",
      "Episode 21700, Avg Reward: 1.838\n",
      "Episode 21800, Avg Reward: 1.831\n",
      "Episode 21900, Avg Reward: 1.841\n",
      "Episode 22000, Avg Reward: 1.834\n",
      "Episode 22100, Avg Reward: 1.828\n",
      "Episode 22200, Avg Reward: 1.829\n",
      "Episode 22300, Avg Reward: 1.833\n",
      "Episode 22400, Avg Reward: 1.827\n",
      "Episode 22500, Avg Reward: 1.833\n",
      "Episode 22600, Avg Reward: 1.824\n",
      "Episode 22700, Avg Reward: 1.832\n",
      "Episode 22800, Avg Reward: 1.825\n",
      "Episode 22900, Avg Reward: 1.825\n",
      "Episode 23000, Avg Reward: 1.848\n",
      "Episode 23100, Avg Reward: 1.829\n",
      "Episode 23200, Avg Reward: 1.827\n",
      "Episode 23300, Avg Reward: 1.840\n",
      "Episode 23400, Avg Reward: 1.842\n",
      "Episode 23500, Avg Reward: 1.824\n",
      "Episode 23600, Avg Reward: 1.829\n",
      "Episode 23700, Avg Reward: 1.836\n",
      "Episode 23800, Avg Reward: 1.830\n",
      "Episode 23900, Avg Reward: 1.841\n",
      "Episode 24000, Avg Reward: 1.827\n",
      "Episode 24100, Avg Reward: 1.823\n",
      "Episode 24200, Avg Reward: 1.835\n",
      "Episode 24300, Avg Reward: 1.832\n",
      "Episode 24400, Avg Reward: 1.829\n",
      "Episode 24500, Avg Reward: 1.841\n",
      "Episode 24600, Avg Reward: 1.837\n",
      "Episode 24700, Avg Reward: 1.828\n",
      "Episode 24800, Avg Reward: 1.825\n",
      "Episode 24900, Avg Reward: 1.828\n",
      "Episode 25000, Avg Reward: 1.826\n",
      "Episode 25100, Avg Reward: 1.827\n",
      "Episode 25200, Avg Reward: 1.831\n",
      "Episode 25300, Avg Reward: 1.842\n",
      "Episode 25400, Avg Reward: 1.837\n",
      "Episode 25500, Avg Reward: 1.832\n",
      "Episode 25600, Avg Reward: 1.837\n",
      "Episode 25700, Avg Reward: 1.834\n",
      "Episode 25800, Avg Reward: 1.833\n",
      "Episode 25900, Avg Reward: 1.833\n",
      "Episode 26000, Avg Reward: 1.831\n",
      "Episode 26100, Avg Reward: 1.833\n",
      "Episode 26200, Avg Reward: 1.843\n",
      "Episode 26300, Avg Reward: 1.837\n",
      "Episode 26400, Avg Reward: 1.834\n",
      "Episode 26500, Avg Reward: 1.843\n",
      "Episode 26600, Avg Reward: 1.836\n",
      "Episode 26700, Avg Reward: 1.836\n",
      "Episode 26800, Avg Reward: 1.835\n",
      "Episode 26900, Avg Reward: 1.841\n",
      "Episode 27000, Avg Reward: 1.826\n",
      "Episode 27100, Avg Reward: 1.836\n",
      "Episode 27200, Avg Reward: 1.837\n",
      "Episode 27300, Avg Reward: 1.827\n",
      "Episode 27400, Avg Reward: 1.830\n",
      "Episode 27500, Avg Reward: 1.839\n",
      "Episode 27600, Avg Reward: 1.840\n",
      "Episode 27700, Avg Reward: 1.843\n",
      "Episode 27800, Avg Reward: 1.827\n",
      "Episode 27900, Avg Reward: 1.832\n",
      "Episode 28000, Avg Reward: 1.826\n",
      "Episode 28100, Avg Reward: 1.825\n",
      "Episode 28200, Avg Reward: 1.833\n",
      "Episode 28300, Avg Reward: 1.822\n",
      "Episode 28400, Avg Reward: 1.837\n",
      "Episode 28500, Avg Reward: 1.828\n",
      "Episode 28600, Avg Reward: 1.831\n",
      "Episode 28700, Avg Reward: 1.828\n",
      "Episode 28800, Avg Reward: 1.830\n",
      "Episode 28900, Avg Reward: 1.828\n",
      "Episode 29000, Avg Reward: 1.827\n",
      "Episode 29100, Avg Reward: 1.828\n",
      "Episode 29200, Avg Reward: 1.824\n",
      "Episode 29300, Avg Reward: 1.838\n",
      "Episode 29400, Avg Reward: 1.829\n",
      "Episode 29500, Avg Reward: 1.823\n",
      "Episode 29600, Avg Reward: 1.839\n",
      "Episode 29700, Avg Reward: 1.841\n",
      "Episode 29800, Avg Reward: 1.837\n",
      "Episode 29900, Avg Reward: 1.841\n",
      "Episode 30000, Avg Reward: 1.823\n",
      "Episode 30100, Avg Reward: 1.827\n",
      "Episode 30200, Avg Reward: 1.826\n",
      "Episode 30300, Avg Reward: 1.827\n",
      "Episode 30400, Avg Reward: 1.835\n",
      "Episode 30500, Avg Reward: 1.833\n",
      "Episode 30600, Avg Reward: 1.841\n",
      "Episode 30700, Avg Reward: 1.840\n",
      "Episode 30800, Avg Reward: 1.828\n",
      "Episode 30900, Avg Reward: 1.844\n",
      "Episode 31000, Avg Reward: 1.840\n",
      "Episode 31100, Avg Reward: 1.827\n",
      "Episode 31200, Avg Reward: 1.834\n",
      "Episode 31300, Avg Reward: 1.833\n",
      "Episode 31400, Avg Reward: 1.834\n",
      "Episode 31500, Avg Reward: 1.826\n",
      "Episode 31600, Avg Reward: 1.824\n",
      "Episode 31700, Avg Reward: 1.833\n",
      "Episode 31800, Avg Reward: 1.819\n",
      "Episode 31900, Avg Reward: 1.839\n",
      "Episode 32000, Avg Reward: 1.844\n",
      "Episode 32100, Avg Reward: 1.829\n",
      "Episode 32200, Avg Reward: 1.837\n",
      "Episode 32300, Avg Reward: 1.833\n",
      "Episode 32400, Avg Reward: 1.832\n",
      "Episode 32500, Avg Reward: 1.834\n",
      "Episode 32600, Avg Reward: 1.827\n",
      "Episode 32700, Avg Reward: 1.831\n",
      "Episode 32800, Avg Reward: 1.826\n",
      "Episode 32900, Avg Reward: 1.834\n",
      "Episode 33000, Avg Reward: 1.829\n",
      "Episode 33100, Avg Reward: 1.838\n",
      "Episode 33200, Avg Reward: 1.834\n",
      "Episode 33300, Avg Reward: 1.830\n",
      "Episode 33400, Avg Reward: 1.837\n",
      "Episode 33500, Avg Reward: 1.829\n",
      "Episode 33600, Avg Reward: 1.835\n",
      "Episode 33700, Avg Reward: 1.833\n",
      "Episode 33800, Avg Reward: 1.825\n",
      "Episode 33900, Avg Reward: 1.818\n",
      "Episode 34000, Avg Reward: 1.830\n",
      "Episode 34100, Avg Reward: 1.823\n",
      "Episode 34200, Avg Reward: 1.833\n",
      "Episode 34300, Avg Reward: 1.827\n",
      "Episode 34400, Avg Reward: 1.839\n",
      "Episode 34500, Avg Reward: 1.837\n",
      "Episode 34600, Avg Reward: 1.824\n",
      "Episode 34700, Avg Reward: 1.829\n",
      "Episode 34800, Avg Reward: 1.833\n",
      "Episode 34900, Avg Reward: 1.835\n",
      "Episode 35000, Avg Reward: 1.827\n",
      "Episode 35100, Avg Reward: 1.837\n",
      "Episode 35200, Avg Reward: 1.833\n",
      "Episode 35300, Avg Reward: 1.832\n",
      "Episode 35400, Avg Reward: 1.837\n",
      "Episode 35500, Avg Reward: 1.836\n",
      "Episode 35600, Avg Reward: 1.836\n",
      "Episode 35700, Avg Reward: 1.827\n",
      "Episode 35800, Avg Reward: 1.831\n",
      "Episode 35900, Avg Reward: 1.825\n",
      "Episode 36000, Avg Reward: 1.829\n",
      "Episode 36100, Avg Reward: 1.837\n",
      "Episode 36200, Avg Reward: 1.847\n",
      "Episode 36300, Avg Reward: 1.835\n",
      "Episode 36400, Avg Reward: 1.821\n",
      "Episode 36500, Avg Reward: 1.837\n",
      "Episode 36600, Avg Reward: 1.828\n",
      "Episode 36700, Avg Reward: 1.823\n",
      "Episode 36800, Avg Reward: 1.828\n",
      "Episode 36900, Avg Reward: 1.842\n",
      "Episode 37000, Avg Reward: 1.831\n",
      "Episode 37100, Avg Reward: 1.842\n",
      "Episode 37200, Avg Reward: 1.822\n",
      "Episode 37300, Avg Reward: 1.825\n",
      "Episode 37400, Avg Reward: 1.840\n",
      "Episode 37500, Avg Reward: 1.833\n",
      "Episode 37600, Avg Reward: 1.833\n",
      "Episode 37700, Avg Reward: 1.842\n",
      "Episode 37800, Avg Reward: 1.829\n",
      "Episode 37900, Avg Reward: 1.837\n",
      "Episode 38000, Avg Reward: 1.837\n",
      "Episode 38100, Avg Reward: 1.838\n",
      "Episode 38200, Avg Reward: 1.837\n",
      "Episode 38300, Avg Reward: 1.853\n",
      "Episode 38400, Avg Reward: 1.828\n",
      "Episode 38500, Avg Reward: 1.837\n",
      "Episode 38600, Avg Reward: 1.843\n",
      "Episode 38700, Avg Reward: 1.842\n",
      "Episode 38800, Avg Reward: 1.826\n",
      "Episode 38900, Avg Reward: 1.827\n",
      "Episode 39000, Avg Reward: 1.820\n",
      "Episode 39100, Avg Reward: 1.834\n",
      "Episode 39200, Avg Reward: 1.834\n",
      "Episode 39300, Avg Reward: 1.834\n",
      "Episode 39400, Avg Reward: 1.833\n",
      "Episode 39500, Avg Reward: 1.830\n",
      "Episode 39600, Avg Reward: 1.838\n",
      "Episode 39700, Avg Reward: 1.831\n",
      "Episode 39800, Avg Reward: 1.845\n",
      "Episode 39900, Avg Reward: 1.834\n",
      "Episode 40000, Avg Reward: 1.832\n",
      "Episode 40100, Avg Reward: 1.833\n",
      "Episode 40200, Avg Reward: 1.829\n",
      "Episode 40300, Avg Reward: 1.833\n",
      "Episode 40400, Avg Reward: 1.837\n",
      "Episode 40500, Avg Reward: 1.837\n",
      "Episode 40600, Avg Reward: 1.843\n",
      "Episode 40700, Avg Reward: 1.836\n",
      "Episode 40800, Avg Reward: 1.827\n",
      "Episode 40900, Avg Reward: 1.840\n",
      "Episode 41000, Avg Reward: 1.848\n",
      "Episode 41100, Avg Reward: 1.833\n",
      "Episode 41200, Avg Reward: 1.835\n",
      "Episode 41300, Avg Reward: 1.833\n",
      "Episode 41400, Avg Reward: 1.837\n",
      "Episode 41500, Avg Reward: 1.844\n",
      "Episode 41600, Avg Reward: 1.838\n",
      "Episode 41700, Avg Reward: 1.833\n",
      "Episode 41800, Avg Reward: 1.834\n",
      "Episode 41900, Avg Reward: 1.821\n",
      "Episode 42000, Avg Reward: 1.834\n",
      "Episode 42100, Avg Reward: 1.833\n",
      "Episode 42200, Avg Reward: 1.830\n",
      "Episode 42300, Avg Reward: 1.843\n",
      "Episode 42400, Avg Reward: 1.824\n",
      "Episode 42500, Avg Reward: 1.830\n",
      "Episode 42600, Avg Reward: 1.847\n",
      "Episode 42700, Avg Reward: 1.825\n",
      "Episode 42800, Avg Reward: 1.837\n",
      "Episode 42900, Avg Reward: 1.835\n",
      "Episode 43000, Avg Reward: 1.838\n",
      "Episode 43100, Avg Reward: 1.833\n",
      "Episode 43200, Avg Reward: 1.841\n",
      "Episode 43300, Avg Reward: 1.837\n",
      "Episode 43400, Avg Reward: 1.832\n",
      "Episode 43500, Avg Reward: 1.827\n",
      "Episode 43600, Avg Reward: 1.827\n",
      "Episode 43700, Avg Reward: 1.830\n",
      "Episode 43800, Avg Reward: 1.835\n",
      "Episode 43900, Avg Reward: 1.830\n",
      "Episode 44000, Avg Reward: 1.827\n",
      "Episode 44100, Avg Reward: 1.835\n",
      "Episode 44200, Avg Reward: 1.833\n",
      "Episode 44300, Avg Reward: 1.836\n",
      "Episode 44400, Avg Reward: 1.833\n",
      "Episode 44500, Avg Reward: 1.825\n",
      "Episode 44600, Avg Reward: 1.828\n",
      "Episode 44700, Avg Reward: 1.836\n",
      "Episode 44800, Avg Reward: 1.827\n",
      "Episode 44900, Avg Reward: 1.829\n",
      "Episode 45000, Avg Reward: 1.839\n",
      "Episode 45100, Avg Reward: 1.828\n",
      "Episode 45200, Avg Reward: 1.837\n",
      "Episode 45300, Avg Reward: 1.833\n",
      "Episode 45400, Avg Reward: 1.823\n",
      "Episode 45500, Avg Reward: 1.832\n",
      "Episode 45600, Avg Reward: 1.833\n",
      "Episode 45700, Avg Reward: 1.827\n",
      "Episode 45800, Avg Reward: 1.837\n",
      "Episode 45900, Avg Reward: 1.837\n",
      "Episode 46000, Avg Reward: 1.835\n",
      "Episode 46100, Avg Reward: 1.834\n",
      "Episode 46200, Avg Reward: 1.829\n",
      "Episode 46300, Avg Reward: 1.825\n",
      "Episode 46400, Avg Reward: 1.826\n",
      "Episode 46500, Avg Reward: 1.840\n",
      "Episode 46600, Avg Reward: 1.834\n",
      "Episode 46700, Avg Reward: 1.831\n",
      "Episode 46800, Avg Reward: 1.833\n",
      "Episode 46900, Avg Reward: 1.830\n",
      "Episode 47000, Avg Reward: 1.846\n",
      "Episode 47100, Avg Reward: 1.831\n",
      "Episode 47200, Avg Reward: 1.832\n",
      "Episode 47300, Avg Reward: 1.835\n",
      "Episode 47400, Avg Reward: 1.833\n",
      "Episode 47500, Avg Reward: 1.831\n",
      "Episode 47600, Avg Reward: 1.837\n",
      "Episode 47700, Avg Reward: 1.833\n",
      "Episode 47800, Avg Reward: 1.835\n",
      "Episode 47900, Avg Reward: 1.837\n",
      "Episode 48000, Avg Reward: 1.831\n",
      "Episode 48100, Avg Reward: 1.840\n",
      "Episode 48200, Avg Reward: 1.819\n",
      "Episode 48300, Avg Reward: 1.832\n",
      "Episode 48400, Avg Reward: 1.836\n",
      "Episode 48500, Avg Reward: 1.829\n",
      "Episode 48600, Avg Reward: 1.840\n",
      "Episode 48700, Avg Reward: 1.845\n",
      "Episode 48800, Avg Reward: 1.832\n",
      "Episode 48900, Avg Reward: 1.844\n",
      "Episode 49000, Avg Reward: 1.837\n",
      "Episode 49100, Avg Reward: 1.841\n",
      "Episode 49200, Avg Reward: 1.825\n",
      "Episode 49300, Avg Reward: 1.836\n",
      "Episode 49400, Avg Reward: 1.823\n",
      "Episode 49500, Avg Reward: 1.834\n",
      "Episode 49600, Avg Reward: 1.828\n",
      "Episode 49700, Avg Reward: 1.838\n",
      "Episode 49800, Avg Reward: 1.837\n",
      "Episode 49900, Avg Reward: 1.823\n",
      "Episode 50000, Avg Reward: 1.843\n"
     ]
    }
   ],
   "source": [
    "policy = WordlePolicy(vocab_size=len(vocab) + 3, embed_dim=32, hidden_dim=64)\n",
    "optimizer = torch.optim.Adam(policy.parameters(), lr=1e-3)\n",
    "env = WordleEnv(word_gen_fn)\n",
    "\n",
    "num_episodes = 50000\n",
    "print_every = 100\n",
    "total_rewards = []\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    env.reset()\n",
    "    log_probs = []\n",
    "    reward = 0\n",
    "\n",
    "    for turn in range(6):\n",
    "        state_tokens = tokenize_history(env.history)\n",
    "        log_action_probs = policy(state_tokens)[..., :len(vocab)]  # restrict to words only\n",
    "        \n",
    "        action_dist = torch.distributions.Categorical(logits=log_action_probs)\n",
    "\n",
    "        action = action_dist.sample()\n",
    "        log_prob = action_dist.log_prob(action)\n",
    "\n",
    "        guess_word = idx2word[action.item()]\n",
    "        feedback, done, reward = env.step(guess_word)\n",
    "\n",
    "        log_probs.append(log_prob)\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # REINFORCE loss: negative log-prob Ã— reward\n",
    "    loss = -torch.stack(log_probs).sum() * reward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    total_rewards.append(reward)\n",
    "\n",
    "    if (episode + 1) % print_every == 0:\n",
    "        avg_reward = sum(total_rewards[-print_every:]) / print_every\n",
    "        print(f\"Episode {episode + 1}, Avg Reward: {avg_reward:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efcec5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agent(policy, env, vocab, idx2word, word2idx, episodes=100):\n",
    "    policy.eval()\n",
    "    successes = 0\n",
    "    total_turns = 0\n",
    "    total_rewards = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(episodes):\n",
    "            env.reset()\n",
    "            for turn in range(6):\n",
    "                state_tokens = tokenize_history(env.history)\n",
    "                if state_tokens.shape[1] == 0:\n",
    "                    state_tokens = torch.tensor([[len(vocab) + 3]], dtype=torch.long)  # START token\n",
    "\n",
    "                log_action_probs = policy(state_tokens)[..., :len(vocab)]\n",
    "                action_dist = torch.distributions.Categorical(logits=log_action_probs)\n",
    "                action = action_dist.sample()\n",
    "                guess_word = idx2word[action.item()]\n",
    "\n",
    "                feedback, done, reward = env.step(guess_word)\n",
    "\n",
    "                if done:\n",
    "                    if guess_word == env.answer:\n",
    "                        successes += 1\n",
    "                        total_turns += len(env.history)\n",
    "                    total_rewards.append(reward)\n",
    "                    break\n",
    "\n",
    "    avg_reward = sum(total_rewards) / episodes\n",
    "    avg_turns = total_turns / successes if successes > 0 else None\n",
    "    print(f\"\\n--- Test Results ---\")\n",
    "    print(f\"Success rate: {successes}/{episodes} ({successes/episodes:.2%})\")\n",
    "    print(f\"Avg reward: {avg_reward:.3f}\")\n",
    "    if avg_turns is not None:\n",
    "        print(f\"Avg turns (successful games): {avg_turns:.2f}\")\n",
    "    else:\n",
    "        print(\"No games were solved.\")\n",
    "\n",
    "    policy.train()  # Reset back to training mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a48dd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test Results ---\n",
      "Success rate: 98/100 (98.00%)\n",
      "Avg reward: 1.769\n",
      "Avg turns (successful games): 2.59\n"
     ]
    }
   ],
   "source": [
    "test_agent(policy, env, vocab, idx2word, word2idx, episodes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086f3cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (wordle-env)",
   "language": "python",
   "name": "wordle-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
